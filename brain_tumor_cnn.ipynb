{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RS4_79vVQty1"
      },
      "outputs": [],
      "source": [
        "! pip install -q kaggle\n",
        "\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "! kaggle datasets download -d masoudnickparvar/brain-tumor-mri-dataset\n",
        "\n",
        "! mkdir mri_dataset\n",
        "\n",
        "! unzip brain-tumor-mri-dataset.zip -d mri_dataset\n",
        "\n",
        "! kaggle datasets download -d rahimanshu/figshare-brain-tumor-classification\n",
        "! mkdir glioma_dataset\n",
        "! unzip figshare-brain-tumor-classification.zip -d glioma_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2XnbU9jyo_C1"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "import sklearn.metrics as skm \n",
        "import seaborn as sns\n",
        "\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from sklearn.utils import shuffle, class_weight\n",
        "import cv2\n",
        "\n",
        "from random import randint\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "%config Completer.use_jedi = False\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-JPByW8nWANj"
      },
      "outputs": [],
      "source": [
        "np.random.RandomState(10)\n",
        "tf.random.set_seed(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6gJMswHht1a5"
      },
      "outputs": [],
      "source": [
        "class_names = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
        "\n",
        "X_treino = []\n",
        "Y_treino = []\n",
        "\n",
        "X_teste = []\n",
        "Y_teste = []\n",
        "\n",
        "image_size = 128\n",
        "\n",
        "glioma_folder_path = os.path.join('/content/glioma_dataset', 'glioma')\n",
        "\n",
        "glioma_images = []\n",
        "for j in tqdm(os.listdir(glioma_folder_path)):\n",
        "    img = cv2.imread(os.path.join(glioma_folder_path,j))\n",
        "    img = cv2.resize(img,(image_size, image_size))\n",
        "    glioma_images.append(img)\n",
        "\n",
        "glioma_labels = ['glioma'] * len(glioma_images)\n",
        "\n",
        "glioma_images_train = glioma_images[:1126]\n",
        "glioma_images_test = glioma_images[1126:1426]\n",
        "\n",
        "glioma_labels_train = glioma_labels[:1126]\n",
        "glioma_labels_test = glioma_labels[1126:1426]\n",
        "\n",
        "X_treino.extend(glioma_images_train)\n",
        "Y_treino.extend(glioma_labels_train)\n",
        "X_teste.extend(glioma_images_test)\n",
        "Y_teste.extend(glioma_labels_test)\n",
        "\n",
        "for i in class_names:\n",
        "    if i != 'glioma':\n",
        "        folderPath = os.path.join('/content/mri_dataset','Training',i)\n",
        "        for j in tqdm(os.listdir(folderPath)):\n",
        "            img = cv2.imread(os.path.join(folderPath,j))\n",
        "            img = cv2.resize(img,(image_size, image_size))\n",
        "            X_treino.append(img)\n",
        "            Y_treino.append(i)\n",
        "\n",
        "        folderPath = os.path.join('/content/mri_dataset','Testing',i)\n",
        "        for j in tqdm(os.listdir(folderPath)):\n",
        "            img = cv2.imread(os.path.join(folderPath,j))\n",
        "            img = cv2.resize(img,(image_size, image_size))\n",
        "            X_teste.append(img)\n",
        "            Y_teste.append(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "tSdUNnYJD38_"
      },
      "outputs": [],
      "source": [
        "X_treino = np.array(X_treino)\n",
        "Y_treino = np.array(Y_treino)\n",
        "\n",
        "X_teste = np.array(X_teste)\n",
        "Y_teste = np.array(Y_teste)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_weights = class_weight.compute_class_weight('balanced',\n",
        "                                                 classes = np.unique(Y_treino),\n",
        "                                                 y = Y_treino)\n",
        "\n",
        "weight = {i : class_weights[i] for i in range(4)}\n",
        "    \n",
        "print(weight)"
      ],
      "metadata": {
        "id": "O_6piHasx1UT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qbX3om2LVMip"
      },
      "outputs": [],
      "source": [
        "Y_treino = np.unique(Y_treino, return_inverse = True)[1]\n",
        "Y_teste = np.unique(Y_teste, return_inverse = True)[1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_treino_count = np.bincount(Y_treino)\n",
        "\n",
        "total = np.sum([Y_treino_count], axis=1)[0]\n",
        "\n",
        "print(\n",
        "    'Examples:\\n    Total: {}\\n    Glioma: {} ({:.2f}% of total)\\n    Meningioma: {} ({:.2f}% of total)\\n    No Tumor: {} ({:.2f}% of total)\\n    Pituitary: {} ({:.2f}% of total)'.format(\n",
        "    total, \n",
        "    Y_treino_count[0], 100 * Y_treino_count[0] / total, \n",
        "    Y_treino_count[1], 100 * Y_treino_count[1] / total, \n",
        "    Y_treino_count[2], 100 * Y_treino_count[2] / total, \n",
        "    Y_treino_count[3], 100 * Y_treino_count[3] / total, ))"
      ],
      "metadata": {
        "id": "y2pIzozZ7Gc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "oqDxMG12sjMV"
      },
      "outputs": [],
      "source": [
        "X_treino = X_treino/255.0\n",
        "X_teste = X_teste/255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7pqmvBXKtFfX"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,20))\n",
        "sum = 1017\n",
        "for i in range(4):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.imshow(X_treino[i + sum])\n",
        "    plt.xlabel(class_names[Y_treino[i + sum]], fontsize=24)\n",
        "\n",
        "    sum = sum + 1350\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "xVfgPuNMigeM"
      },
      "outputs": [],
      "source": [
        "def get_model():\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(16, kernel_size=(3, 3), activation='relu', \n",
        "                    input_shape=(image_size,image_size,3), padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), padding='same'))\n",
        "    model.add(Dropout(0.20))\n",
        "\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "    model.add(Dropout(0.30))\n",
        "\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))             \n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "    model.add(Dropout(0.40))\n",
        "\n",
        "    model.add(Flatten())\n",
        "\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dropout(0.60))\n",
        "\n",
        "    model.add(Dense(4, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics = ['accuracy'])\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#! pip install visualkeras\n",
        "\n",
        "#import visualkeras\n",
        "#from PIL import ImageFont\n",
        "\n",
        "model = get_model()\n",
        "\n",
        "#font = ImageFont.truetype(\"Roboto-Regular.ttf\", 24)\n",
        "#visualkeras.layered_view(model, legend=True, font=font)\n",
        "\n",
        "#model.summary()\n",
        "#plot_model(model, to_file='model_plot.png', show_shapes = True, \n",
        "#           show_layer_names = False, show_layer_activations = True)"
      ],
      "metadata": {
        "id": "IdKwHXdN6i3j"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "erlstp = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=18)\n",
        "\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.2,\n",
        "                              patience=5)\n",
        "\n",
        "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath='weights/weights.hdf5',\n",
        "    verbose=1,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True\n",
        ")"
      ],
      "metadata": {
        "id": "9lTZhdZRD44t"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_and_evaluate(t_x, val_x, t_y, val_y, EPOCHS, BATCH_SIZE, class_w):\n",
        "    model = None\n",
        "    model = get_model()\n",
        "    results = model.fit(t_x, t_y, epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
        "                validation_data = (val_x, val_y),\n",
        "                class_weight=class_w,\n",
        "                callbacks=[erlstp, reduce_lr, model_checkpoint], verbose=1)  \n",
        "    \n",
        "    print(\"\\nValidation Score: \", model.evaluate(val_x, val_y))\n",
        "    return results"
      ],
      "metadata": {
        "id": "-agDu7cUAQns"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_folds=5\n",
        "epochs=100\n",
        "batch_size=32\n",
        "\n",
        "model_history = [] \n",
        "\n",
        "for i in range(n_folds):\n",
        "    print(\"Training on Fold: \", i + 1)\n",
        "\n",
        "    X_t, X_v, label_t, label_v = train_test_split(\n",
        "      X_treino, Y_treino, test_size = 0.2, random_state = 13\n",
        "    )\n",
        "\n",
        "    X_t, label_t = shuffle(X_t, label_t, random_state = 13)\n",
        "                                               \n",
        "    model_history.append(fit_and_evaluate(X_t, X_v, label_t, label_v, epochs, batch_size, weight))\n",
        "    print(\"=======\" * 12, end=\"\\n\\n\\n\")"
      ],
      "metadata": {
        "id": "kIZ4Ljtr_y6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "colors = ['black', 'red', 'green', 'purple', 'gray']\n",
        "labels = ['Fold 1', 'Fold 2', 'Fold 3', 'Fold 4', 'Fold 5']\n",
        "\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.title('Train Loss vs Val Loss')\n",
        "for i, color in enumerate(colors):\n",
        "    plt.plot(model_history[i].history['loss'], label='Train Loss '+labels[i], color=color)\n",
        "    plt.plot(model_history[i].history['val_loss'], label='Val Loss '+labels[i], color=color, linestyle = \"dashdot\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.title('Train Accuracy vs Val Accuracy')\n",
        "for i, color in enumerate(colors):\n",
        "    plt.plot(model_history[i].history['accuracy'], label='Train Accuracy '+labels[i], color=color)\n",
        "    plt.plot(model_history[i].history['val_accuracy'], label='Val Accuracy '+labels[i], color=color, linestyle = \"dashdot\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "R2zUCgimG_1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Load the model that was saved by ModelCheckpoint\n",
        "model = load_model('weights/weights.hdf5')\n",
        "\n",
        "results = model.evaluate(X_teste, Y_teste)\n",
        "print(\"Loss: {:0.4f}\".format(results[0]))"
      ],
      "metadata": {
        "id": "tzC-OMU8R5c5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjbNOSCqSHxk"
      },
      "outputs": [],
      "source": [
        "# Testando o modelo com o conjunto de teste, separado anteriormente\n",
        "\n",
        "predicted_classes = model.predict(X_teste)\n",
        "predicted_classes = np.argmax(np.round(predicted_classes), axis = 1)\n",
        "\n",
        "print(classification_report(Y_teste, predicted_classes, target_names = class_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWCzHsjB1tGP"
      },
      "outputs": [],
      "source": [
        "# Gerando e apresentando a matriz de confusão\n",
        "\n",
        "cmat = confusion_matrix(Y_teste, predicted_classes)\n",
        "cm_df = pd.DataFrame(cmat) \n",
        "\n",
        "cmat_df = pd.DataFrame(cmat,\n",
        "                     index = class_names, \n",
        "                     columns = class_names)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "\n",
        "sns.heatmap(cmat, annot = True, cmap = 'Blues', fmt = \"d\",\n",
        "            cbar = False,\n",
        "            xticklabels = class_names,\n",
        "            yticklabels = class_names)\n",
        "\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "    with tf.GradientTape() as tape:\n",
        "        last_conv_layer_output, preds = grad_model(img_array)\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(preds[0])\n",
        "        class_channel = preds[:, pred_index]\n",
        "\n",
        "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
        "\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    last_conv_layer_output = last_conv_layer_output[0]\n",
        "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "\n",
        "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
        "    return heatmap.numpy()"
      ],
      "metadata": {
        "id": "4NfLuJUOlVmT"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread('/content/mri_dataset/Testing/meningioma/Te-me_0025.jpg')\n",
        "orig_img = img\n",
        "img = cv2.resize(img, (image_size, image_size))\n",
        "\n",
        "img = img.astype('float32') / 255.0\n",
        "\n",
        "x = np.array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "\n",
        "layer_name = 'conv2d_6'\n",
        "\n",
        "heatmap = make_gradcam_heatmap(x, model, layer_name)\n",
        "\n",
        "orig_img = cv2.cvtColor(orig_img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "heatmap_colored = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)\n",
        "heatmap_colored = cv2.cvtColor(heatmap_colored, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "heatmap_resized = cv2.resize(heatmap_colored, (orig_img.shape[1], orig_img.shape[0]))\n",
        "\n",
        "superimposed_img = np.uint8(heatmap_resized * 0.5 + orig_img)\n",
        "\n",
        "plt.imshow(superimposed_img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ds2BB-talAU6"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}